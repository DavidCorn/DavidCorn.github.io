<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>这个月看的书 | 2020.02</title>
    <url>/2020/03/01/%E8%BF%99%E4%B8%AA%E6%9C%88%E7%9C%8B%E7%9A%84%E4%B9%A6-2020-02/</url>
    <content><![CDATA[<p>这个月只看了一本 。。。</p>
<h3 id="01-六里庄遗事"><a href="#01-六里庄遗事" class="headerlink" title="01 | 六里庄遗事"></a>01 | 六里庄遗事</h3><p>这本书虚构了一个叫做六里庄的村子，用五百多个小故事勾勒出了形形色色的人生轶事。作者在一篇文章中曾讲过自己读很多笔记小说的时候，很多都只有十分平常的记录，某年某月某事，如此而已。比起关注事件本身，作者更希望去抓取记录非决定性瞬间。那些平常的时刻蕴含着更大、更深邃的力量。我们的人生里处处都是闲笔，而我们就存在于这些闲笔里。</p>
<p>这本书里大多数故事都是口语风格的对话，一两百字虽然精短但兼具温度和重量。许许多多个零碎的故事读完，一个云山雾绕的小村庄就神奇地在脑海中浮现了出来：活了千百年的杨温柔，总是遇到善良温柔鬼混的金道士，喜欢写烂俗诗词的石胖子还有为螃蟹超度的法聪小僧。</p>
<p>摘录一个最五味杂陈的小故事结尾吧。</p>
<blockquote>
<p>吴不利他爸吴伯昭三十三岁那年犯起了腰腿疼，起初是麻，后来是瘸，三五个月就起不来床了。 </p>
<p>吴不利有个表舅叫徐松年，本来走动并不多，但自打吴伯昭没法下床，就常来探望。有时候留下吃顿饭，有时候看看就走。最后一次来是腊月初七。腊月初九那天晚上吴不利他妈给吴伯昭端来一碗药，说药给你熬好了，你喝了吧。吴伯昭瞧了药一眼，又瞧了她一眼，说你放下吧，我一会儿就喝。吴不利他妈说赶紧喝吧，一会儿就凉了。吴伯昭说没事，凉了一样治病。又说，你放心。 </p>
<p>那碗药，吴伯昭第二天早上才喝。寒冬腊月，碗里已经冻上冰碴儿了，吴伯昭就慢慢地喝，一小口一小口地抿，含在嘴里，含热了再咽下去。好容易喝完了，就喊吴不利他妈，说兰儿啊，你过来拿碗吧，药我喝完了。吴不利他妈过来，说：非得今天早上再喝，冰凉凉的，喝了多难受。吴伯昭乐了，说：嘿嘿，我怕昨晚喝了，你守着尸首睡一夜，害怕。又说：你往药里放他拿来的那包东西，我瞧见了。吴不利他妈看着手里的碗，说：那你还喝？吴伯昭又乐了：喝呗，你放都放了。 </p>
</blockquote>
]]></content>
      <categories>
        <category>这个月看的书</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>这个月看的书 | 2020.01</title>
    <url>/2020/02/17/%E8%BF%99%E4%B8%AA%E6%9C%88%E7%9C%8B%E7%9A%84%E4%B9%A6-2020-01/</url>
    <content><![CDATA[<p>今年的愿望清单之一是每个月记录自己读过的书。灵感来源于一个很喜欢的公众号<a href="https://wemp.app/accounts/1ed4d3ff-f77a-4de4-94fc-70733be026cd" target="_blank" rel="noopener">大胡子阿细</a>。很多书理所当然也来自公众号的清单。技术类书籍值得写的会单独开一个专栏，这里就记录一些杂七杂八琐碎的东西好了。</p>
<h3 id="01-情人"><a href="#01-情人" class="headerlink" title="01 | 情人"></a>01 | 情人</h3><p>开始看杜拉斯完全是因为《杜拉斯谈杜拉斯》这本访谈录。我一直对极度自我甚至自恋的作家有很大的好感。去年年底回国带回了《情人》和《广岛之恋》。</p>
<p>整本书无时无刻透露着一种克制冷静却又充满力量的叙事方式，以及强烈的个性和自恋交织而成的矛盾。杜拉斯访谈中不止一次提到这本书里有许多她自己的故事和经历的线索。这本小说莫名让我想到伍琦诗的《无声告白》。一个非常相似的地方在于，两位作者都美得让人惊艳。</p>
<p>与其说是在写自己和中国情人的故事，不如说是一本关于自我价值，成长的审视。</p>
<h3 id="02-海与毒药"><a href="#02-海与毒药" class="headerlink" title="02 | 海与毒药"></a>02 | 海与毒药</h3><p>我强烈地觉得这本书有过誉之嫌——相比于远藤周作的《深河》与《沉默》。也可能是后两部书带来的震撼太过强烈，反战题材的《海与毒药》显得没有那么深刻。一想起《深河》和《沉默》，我脑海中就涌现出背负异教徒前往恒河的背影，以及在日本监牢里目睹生死带来的压迫感。</p>
<p>这本书讲述的是一个参与侵华战争活体实验的医生的回忆。对于色调和叙事节奏的把握有着十分浓厚的的日式风格。印象最深的是开篇一段老医生给患者进行气胸疗法的描写，精准、冷酷、专业。如果医学的突破建立在非人道实验的基础上，我们究竟应该以什么样的心态来面对？</p>
<h3 id="03-绿毛水怪"><a href="#03-绿毛水怪" class="headerlink" title="03 | 绿毛水怪"></a>03 | 绿毛水怪</h3><p>《绿毛水怪》是一个短篇小说集的手稿，里面我个人最喜欢的是绿毛水怪和地久天长。故事讲述的是6、70年代纯真而又热烈的爱情，从王小波的其他作品中，也不常见到如此外放的诗意了。</p>
<blockquote>
<p>白天下了一场雨。可是晚上又很冷。没有风。结果是起了雨雾。天黑得很早。沿街楼房的窗户上喷着一团团白色的光。大街上，水银灯在在半天织起了冲天的白雾。人、汽车隐隐约约地出现和消失。我们走到十路汽车站旁。几盏昏暗的路灯下，人们就像在水底一样。</p>
</blockquote>
<blockquote>
<p>我们无言地走着，妖妖忽然问我：“你看这个夜雾，我们怎么形容它呢？”我鬼使神差地做起诗来，并且马上念出来。要知道我过去根本不认为自己有一点作诗的天分。</p>
</blockquote>
<blockquote>
<p>我说：“妖妖，你看那水银灯的灯光像什么？大团的蒲公英浮在街道的河流口，吞吐着柔软的针一样的光。”妖妖说：“好，那么我们在人行道上走呢？这昏吰的路灯呢？”</p>
</blockquote>
<blockquote>
<p>我抬头看看路灯，它把昏黄的灯光隔着蒙蒙的雾气一直投向地面。我说：“我们好象在池塘的水底。从一个月亮走向另一个月亮。”</p>
</blockquote>
<blockquote>
<p>妖妖忽然大惊小怪地叫起来：“陈辉，你是诗人呢！”我说：“我是诗人？不错，当然我是诗人。”</p>
</blockquote>
<blockquote>
<p>“你怎么啦？我说真的呢！你很可以做一个不坏的诗人。你有真正的诗人气质！”</p>
</blockquote>
]]></content>
      <categories>
        <category>这个月看的书</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>如何从Hive中获取最大分区数据</title>
    <url>/2019/12/28/%E5%A6%82%E4%BD%95%E4%BB%8EHive%E4%B8%AD%E8%8E%B7%E5%8F%96%E6%9C%80%E5%A4%A7%E5%88%86%E5%8C%BA%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<h1 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h1><p>最近在工作中遇到了这样一个场景：我们有一个Hive table，分区 (partition) 按照日期划分。ETL pipeline需要在执行过程中选择日期最近的分区数据。在Spark环境下，最直接的做法是这样的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">most_recent_date = spark.sql(</span><br><span class="line">	<span class="string">"SELECT max(partition_name) from table_name"</span></span><br><span class="line">).first()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然在实际代码中不要使用 SELECT * 这种语法，这里只是为了方便起见。</span></span><br><span class="line">result = spark.sql(</span><br><span class="line">	<span class="string">"""</span></span><br><span class="line"><span class="string">	SELECT * FROM table_name where partition_name = &#123;partition&#125;</span></span><br><span class="line"><span class="string">	"""</span>.format(partition=most_recent_date)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>利用Spark进行数据处理，对3TB/单一partition的数据集，花费时间为117s。在查阅相关资料<sup>[1]</sup>后我发现还有另外一种做法，通过show table的方式拿到所有的partition然后选择最新的partition。PySpark实现方法如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">most_recent_date = spark.sql(</span><br><span class="line">	<span class="string">"SHOW PARTITIONS table_name"</span></span><br><span class="line">).rdd.flatMap(</span><br><span class="line">	<span class="keyword">lambda</span> x: x</span><br><span class="line">).map(</span><br><span class="line">	<span class="keyword">lambda</span> x: x.replace(<span class="string">'partition_name='</span>, <span class="string">''</span>)</span><br><span class="line">).max()</span><br><span class="line"></span><br><span class="line">result = spark.sql(</span><br><span class="line">	<span class="string">"""</span></span><br><span class="line"><span class="string">	SELECT * FROM table_name where partition_name = &#123;partition&#125;</span></span><br><span class="line"><span class="string">	"""</span>.format(partition=most_recent_date)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>用同样的数据集进行测试，花费时间降低到了0.2s。之所以有这么大的改进，原因要从Hive的架构说起。</p>
<h1 id="Hive架构"><a href="#Hive架构" class="headerlink" title="Hive架构"></a>Hive架构</h1><p><img alt="Hive Architecture" title="Hive Architecture" data-src="/images/hive_arch.png" class="lazyload"></p>
<p>Hive的架构可以大致分为四层：</p>
<ol>
<li>用户接口 (CLI，JDBC)。用户可以通过终端交互(CLI)的方式与Hive进行连接，同时Hive也有基于JDBC (Java Database Connectivity)连接至Hive的服务；</li>
<li>驱动引擎 Driver。Hive的驱动引擎包含了解析、编译、优化和执行，生成等过程；</li>
<li>计算层。计算层Hive支持MapReduce，Tez，Spark等多种计算引擎；</li>
<li>存储层。Hive数据存储包括两个方面，一个是元数据的存储，另一个是数据的持久化。</li>
</ol>
<p>值得注意的是，在客户端与Driver之间，存在着跨语言服务 (thrift server)，集成多种语言帮助用户调用Hive接口。接下来我们主要来看存储层。</p>
<h2 id="元数据-Metadata-的存储"><a href="#元数据-Metadata-的存储" class="headerlink" title="元数据 (Metadata) 的存储"></a>元数据 (Metadata) 的存储</h2><p>Hive元数据主要包括表名，列和分区的属性，以及表的属性（内部表还是外部表）等等。数据库、表、分区对应HDFS下的目录。</p>
<p>Hive的元数据默认会存在Hive自带的Derby数据库中。Derby存在的问题是多用户连接操作支持不是很好，并且数据库目录不固定，不方便管理。一般生产环境中我们使用Mysql存储元数据。Mysql与Hive之间通过metastore进行交互。</p>
<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p><img alt="Hive Data Model" title="Hive Data Model" data-src="/images/hive_data_model.png" class="lazyload"></p>
<p>Hive的数据存储在HDFS中，基本存储单位为表或者分区。表或者分区在Hive内部被称为SD<sup>[2]</sup> (Storage Descriptor)。SD的基本信息存储在metastore中。Hive到底层数据的查询都会转化成MapReduce或者Tez/Spark的作业。</p>
<p>从以上介绍可以发现一点，当我们使用Hive SHOW PARTITION的时候，查询并不会跑到HDFS，而是<strong>直接与metastore进行交互拿到分区的信息</strong>，省略了MapReduce任务和各种编译、优化的环节，大大提高了查询速度。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>元数据尽量从metastore中读取，<code>SELECT *</code>并不是万金油；</li>
<li>Hive适用于大规模数据的ETL，offline query和需要离线精确结果的场景。如果需要交互式adhoc查询最好移步Presto, Impala；</li>
</ol>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>[1] <a href="https://stackoverflow.com/questions/55053218/pyspark-getting-latest-partition-from-hive-partitioned-column-logic" target="_blank" rel="noopener">https://stackoverflow.com/questions/55053218/pyspark-getting-latest-partition-from-hive-partitioned-column-logic</a> “pyspark - getting Latest partition from Hive partitioned column logic”</li>
<li>[2] <a href="https://www.jianshu.com/p/4ce73f4d0bd5" target="_blank" rel="noopener">https://www.jianshu.com/p/4ce73f4d0bd5</a> “Hive原理及SQL优化”</li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Apache Spark</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang调度器原理解析</title>
    <url>/2019/12/25/Golang%E8%B0%83%E5%BA%A6%E5%99%A8%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="什么是Goroutine"><a href="#什么是Goroutine" class="headerlink" title="什么是Goroutine"></a>什么是Goroutine</h3><p>Goroutine可以看作是轻量级的抽象thread。在编写Go代码的时候，我们会对Goroutine进行操作而不是针对thread。对于操作系统而言，thread是最小的调度单位。所以可以认为goroutine是用户层面的线程抽象。</p>
<h3 id="Goroutine和thread的区别"><a href="#Goroutine和thread的区别" class="headerlink" title="Goroutine和thread的区别"></a>Goroutine和thread的区别</h3><p>Goroutine与thread之间的区别<sup>[1]</sup>主要可以从三个方面出发，如下表所示：</p>
<table>
<thead>
<tr>
<th>区别</th>
<th>Goroutine</th>
<th>Thread</th>
</tr>
</thead>
<tbody><tr>
<td>内存占用</td>
<td>占用2KB栈内存，根据需要在运行中扩容</td>
<td>占用1MB左右内存，同时创建guard page与其他线程隔离</td>
</tr>
<tr>
<td>创建和销毁</td>
<td>Go runtime负责管理，用户级资源，创建销毁消耗非常小</td>
<td>内核级，消耗很大</td>
</tr>
<tr>
<td>切换成本</td>
<td>只需要保存三个寄存器 (register)，一般200ns左右</td>
<td>需要保存各种寄存器，消耗1000-1500ns</td>
</tr>
</tbody></table>
<h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p>关于调度器有三种基本模型：</p>
<ol>
<li>N:1。也就是多个用户线程对应一个系统线程。优势在于上下文切换快，缺点在于难以发挥多核处理器的优势；</li>
<li>1:1。也就是一个用户线程对应一个系统线程。牺牲上下文切换成本，充分利用多核处理器的优势；</li>
<li>M:N。理论上能在上下文切换和多核处理器之间找到平衡。</li>
</ol>
<p>Thread与Goroutine之间是一个M:N的关系。Go程序启动的时候，runtime会创建M个thread，之后创建的N个Goroutine会依附于这M个thread上执行。总的说来，Go runtime维护所有的Goroutine，通过scheduler进行调度。Goroutine与thread相互独立，但是Goroutine依托thread进行执行。</p>
<p>同一时刻一个thread上只能有一个Goroutine被执行。这时候什么thread上执行哪一个Goroutine，如何进行上下文的切换需要有一个中间人Scheduler做调度。Scheduler的调度也是Go程序高效执行的关键之一。</p>
<h2 id="调度器（Scheduler）"><a href="#调度器（Scheduler）" class="headerlink" title="调度器（Scheduler）"></a>调度器（Scheduler）</h2><h3 id="调度模型MPG"><a href="#调度模型MPG" class="headerlink" title="调度模型MPG"></a>调度模型MPG</h3><p>Golang的scheduler主要由三个部分组成：</p>
<ol>
<li>M（Machine）代表OS thread；</li>
<li>P（Processer）代表调度器（context for scheduling），通常P的数量等于CPU核数（<strong>GOMAXPROCS</strong>）；</li>
<li>G （Goroutine）代表Goroutine。</li>
</ol>
<p>他们的具体关系如下图所示<sup>[2]</sup>:</p>
<p><img alt="MPG Model" title="MPG Model" data-src="/images/mpg_scheduler.jpg" class="lazyload"></p>
<p>上图揭示了几个要点<sup>[3]</sup>：</p>
<ol>
<li>G需要绑定在M上才能运行；</li>
<li>M需要绑定在P上才能运行；</li>
<li>程序中多个M并不会同时处于运行状态，最多只有 <em>GOMAXPROCS</em> 个M在运行。</li>
</ol>
<p>在Go 1.1之前并没有P的存在。调度是由G与M共同完成。Global维护一个runqueue，当M需要G的时候便从runqueue中获取。这时候需要一个全局所来保护调度对象。很明显，全局锁的存在严重影响了Goroutine的并发性能。Go 1.1之后Dmitry Vyukov<sup>[4]</sup>设计了Processor对原先的Go scheduling进行了改进，使得每一个M上绑定一个P，P会维护一个runnable状态的G队列（Local Runnable Queue, LRQ），解决了原先全局锁的问题。</p>
<h3 id="调度算法（Work-stealing）"><a href="#调度算法（Work-stealing）" class="headerlink" title="调度算法（Work-stealing）"></a>调度算法（Work-stealing）</h3><p>通过引入P，实现的work-stealing调度算法如下：</p>
<ol>
<li>每一个P维护一个可运行队列LRQ；</li>
<li>当一个G生成时将其放入一个P的LRQ中；</li>
<li>当一个G执行结束时P会从队列中把G取出，如果P队列为空则会随机选择另外一个P偷取他一半的G；</li>
</ol>
<p>Work-stealing本质上来讲是一个负载均衡的算法。除了LRQ之外runttime也会维护一个GRQ（Global Runnable Queue）存放没有被分配具体P的G。</p>
<h3 id="同步系统调度（Blocking-System-Call）"><a href="#同步系统调度（Blocking-System-Call）" class="headerlink" title="同步系统调度（Blocking System Call）"></a>同步系统调度（Blocking System Call）</h3><p>之所以P存在，是当有M被sysCall block的时候，我们能够把整个P交给另外一个M继续执行。当sysCall执行完毕后M会偷取其他的P，如果无法找到合适的P，M会进入线程池休眠。</p>
<p><img alt="Blocking System Call" title="Blocking System Call" data-src="/images/syscall.jpg" class="lazyload"></p>
<h3 id="异步系统调度（Asyn-System-Call）"><a href="#异步系统调度（Asyn-System-Call）" class="headerlink" title="异步系统调度（Asyn System Call）"></a>异步系统调度（Asyn System Call）</h3><p>如果是异步调用，M不会被阻塞。如图所示，G1的异步请求会被Network Poll接手，M此时会继续执行G2，当G1异步请求完成，会自动放回P的LRQ中，整个过程如下图所示<sup>[5]</sup>。</p>
<p><img alt="Async System Call" title="Async System Call" data-src="/images/async_syscall.png" class="lazyload"></p>
<h3 id="抢占式调度（Takeover）"><a href="#抢占式调度（Takeover）" class="headerlink" title="抢占式调度（Takeover）"></a>抢占式调度（Takeover）</h3><p>Goroutine的执行是可以被抢占<sup>[3]</sup>的。简单来说，如果一个Goroutine占用CPU时间过长（&gt; 10ms），P长时间没有进行调度，runtime会将其抢占，把CPU时间交给其他Goroutine。</p>
<p>具体来看，runtime启动时，程序会创建一个系统线程，运行<code>sysmon()</code>函数，负责监控所有Goroutine的状态同时判断是否需要进行垃圾回收。如果G执行时间过长，<code>sysmon()</code>会对这个G进行标记，下一次函数调用的时候会自动失败，并且和对应的M解除绑定关系并移送全局可执行队列GRQ中，然后为P设置新的可执行G。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Go并发效率如此之高，我们可以做一个简单的总结：</p>
<ol>
<li>Goroutine相较线程来看更为轻量，创建、销毁以及上下文切换开销小很多；</li>
<li>Scheduler实现了M:N的调度模式（并行能力由GOMAXPROCS决定，也就是多少个Processor），兼顾N:1，1:1调度模型优点，整体运行效率比线程调度高很多。</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>[1] <a href="https://blog.nindalf.com/posts/how-goroutines-work/" target="_blank" rel="noopener">https://blog.nindalf.com/posts/how-goroutines-work/</a> “How Goroutines Work”</li>
<li>[2] <a href="https://morsmachine.dk/go-scheduler" target="_blank" rel="noopener">https://morsmachine.dk/go-scheduler</a> “The Go scheduler”</li>
<li>[3] <a href="https://cloud.tencent.com/developer/article/1165575" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1165575</a> “Go runtime scheduler”</li>
<li>[4] <a href="https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit" target="_blank" rel="noopener">https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit</a> “Scalable Go Scheduler Design Doc”</li>
<li>[5] <a href="https://qcrao.com/2019/09/02/dive-into-go-scheduler/" target="_blank" rel="noopener">https://qcrao.com/2019/09/02/dive-into-go-scheduler/</a> “深度解密Go语言之scheduler”</li>
</ul>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title>高并发系统的降级处理——减载</title>
    <url>/2019/12/19/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%99%8D%E7%BA%A7%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%87%8F%E8%BD%BD/</url>
    <content><![CDATA[<p>在服务器流量波动的情况下，我们需要根据下游服务器容量、业务要求等等对系统进行策略性的保护。保护策略有很多种，包括：</p>
<ol>
<li>限流（Rate limit）：限制系统输入输出以达到维持服务稳定的目的；</li>
<li>熔断（Circuit break）：在系统受到过多failing response的时候，拒绝系统输出；</li>
<li>减载（Load shedding）：在系统输入请求响应时间过长的时候，拒绝系统输入。</li>
</ol>
<p>一旦系统处理速度小于系统每秒接收的请求数量（processing speed &lt; QPS），内存队列中的请求将逐渐累积，当请求不断增加没有及时释放，系统会遇到延迟增高，阻塞，内存溢出等等问题。因此系统可以建立一种机制，在响应时间变长时拒绝接收请求防止系统过载。</p>
<p>Facebook 有一篇非常有名的paper <sup>[1]</sup>提供了集中策略来设计系统减载方案（loadshedding）。主要里用到的技术包含Control Delay（CoDel）和Adaptive LIFO。</p>
<h1 id="Control-Delay"><a href="#Control-Delay" class="headerlink" title="Control Delay"></a>Control Delay</h1><p>一般来说服务器会有内存或者资源池数量的限制，并将没有来得及处理的请求放在缓冲区。一旦处理请求的速度跟不上到来的请求，队列将会越来越大并且最终超过使用闲置。Facebook根据CoDel的启发设计了一套算法：</p>
<ol>
<li>当内存缓冲队列在过去的N毫秒内没有被清空，则queue中请求的timeout则被设置为M毫秒（一般为10-30ms）；</li>
<li>(Optional) 当内存缓冲队列在过去的N毫秒内被清空，则queue中请求的timeout被设置成N毫秒。</li>
</ol>
<p>伪代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">onNewRequest</span><span class="params">(req, queue)</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (queue.lastEmptyTime() &lt; (now - N seconds)) &#123;</span><br><span class="line">     timeout = M ms</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     timeout = N seconds;</span><br><span class="line">  &#125;</span><br><span class="line">  queue.enqueue(req, timeout)</span><br></pre></td></tr></table></figure>

<h1 id="Adaptive-LIFO"><a href="#Adaptive-LIFO" class="headerlink" title="Adaptive LIFO"></a>Adaptive LIFO</h1><p>大部分系统处理请求遵循FIFO (First In Last Out) 原则。在峰值流量太大时，后来的请求可能会因为先来请求的阻塞而导致请求耗时更长。对此Facebook提出的方案是adaptive LIFO (Last In First Out) ，当系统出现队列请求积压的时候，将队列模式自动切换为LIFO，后到的请求首先执行，最大限度上增加了请求成功的可能性。</p>
<p>Adaptive LIFO与CoDel能够非常好的兼容，如下图所示。CoDel设置较短timeout，防止队列积压过多请求，adaptive LIFO将后入的请求率先处理，最大限度增加请求成功的概率。Facebook的PHP runtime virtual machine <sup>[2]</sup>以及thrift <sup>[3]</sup> framework都用到了这种算法。</p>
<p><img alt="Adaptive LIFO" title="Adaptive LIFO" data-src="/images/adaptive_lifo.png" class="lazyload"></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>[1] <a href="https://queue.acm.org/detail.cfm?id=2839461" target="_blank" rel="noopener">https://queue.acm.org/detail.cfm?id=2839461</a> “Fail at Scale”</li>
<li>[2] <a href="https://github.com/facebook/hhvm/blob/43c20856239cedf842b2560fd768038f52b501db/hphp/util/job-queue.h#L75" target="_blank" rel="noopener">https://github.com/facebook/hhvm/blob/43c20856239cedf842b2560fd768038f52b501db/hphp/util/job-queue.h#L75</a> “A virtual machine for executing programs written in Hack”</li>
<li>[3] <a href="https://github.com/facebook/fbthrift" target="_blank" rel="noopener">https://github.com/facebook/fbthrift</a> “Facebook Thrift”</li>
</ul>
]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title>高并发系统的降级处理——熔断</title>
    <url>/2019/12/15/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%99%8D%E7%BA%A7%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E7%86%94%E6%96%AD/</url>
    <content><![CDATA[<p>在服务器流量波动的情况下，我们需要根据下游服务器容量、业务要求等等对系统进行策略性的保护。保护策略有很多种，包括：</p>
<ol>
<li>限流（Rate limit）：限制系统输入输出以达到维持服务稳定的目的；</li>
<li>熔断（Circuit break）：在系统受到过多failing response的时候，拒绝系统输出；</li>
<li>减载（Load shedding）：在系统输入请求响应时间过长的时候，拒绝系统输入。</li>
</ol>
<p>熔断的作用是阻止服务发送过多可能失败的请求 (The Circuit Breaker pattern prevents an application from performing an operation that is likely to fail)。本文从开源代码 <a href="https://github.com/sony/gobreaker" target="_blank" rel="noopener">sony/gobreaker</a> <sup>[1]</sup>出发，介绍熔断器的工作原理和机制。</p>
<h1 id="设计要求-Requirements"><a href="#设计要求-Requirements" class="headerlink" title="设计要求 (Requirements)"></a>设计要求 (Requirements)</h1><p>分布式系统中，一般的故障场景例如网络波动（slow network connection），请求超时（timeout）或者过载（overload）等等都可能是暂时性的问题，能够通过系统自修复或者云系统的延展性（horizontal/vertical scaling）等等方式解决。熔断器（Circuit Breaker）是为了解决一些不可预测、难以自修复的故障，比如系统下游服务不可用，数据库宕机等等。另外，熔断器也能有效地阻止连锁反应（cascading failure）的发生。比如当网关（gateway）某一个下游服务不可用，系统不断发送请求并不断重试，可能会导致网关服务占用过多资源内存导致整体崩溃；下游服务如果只是部分不可用，过多的失败请求也会导致下游服务崩溃。</p>
<p>设计一个熔断器要求能够在故障时迅速反应，并且在故障恢复后能够自动恢复。</p>
<h1 id="状态机-State-machine"><a href="#状态机-State-machine" class="headerlink" title="状态机 (State machine)"></a>状态机 (State machine)</h1><p>熔断器其实是一个小型的状态机，随着请求返回状态码动态进行状态的调整。状态可以分为三类：闭合（Closed），开启（Open），半开（Half-open）。相互关系如下图<sup>[2]</sup>所示。</p>
<p><img alt="Circuit breaker state machine" title="Circuit breaker state machine" data-src="/images/circuit_breaker.png" class="lazyload"></p>
<p>每次请求到来的时候熔断器会有两个内置函数<code>before_request</code>以及<code>after_request</code>。<code>before_request</code>在请求前进行调用，根据状态决定是否截断请求，并记录请求数量。<code>after_request</code>作用在请求结束之后，负责根据请求返回状态码进行状态和计数器的更新。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Execute runs the given request if the CircuitBreaker accepts it.</span></span><br><span class="line"><span class="comment">// Execute returns an error instantly if the CircuitBreaker rejects the request.</span></span><br><span class="line"><span class="comment">// Otherwise, Execute returns the result of the request.</span></span><br><span class="line"><span class="comment">// If a panic occurs in the request, the CircuitBreaker handles it as an error</span></span><br><span class="line"><span class="comment">// and causes the same panic again.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cb *CircuitBreaker)</span> <span class="title">Execute</span><span class="params">(req <span class="keyword">func</span>()</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span>) <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span> &#123;</span><br><span class="line">	generation, err := cb.beforeRequest()</span><br><span class="line">	<span class="comment">//...</span></span><br><span class="line">	</span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		e := <span class="built_in">recover</span>()</span><br><span class="line">		<span class="keyword">if</span> e != <span class="literal">nil</span> &#123;</span><br><span class="line">			cb.afterRequest(generation, <span class="literal">false</span>)</span><br><span class="line">			<span class="built_in">panic</span>(e)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	cb.afterRequest(generation, err == <span class="literal">nil</span>)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="闭合（Closed）"><a href="#闭合（Closed）" class="headerlink" title="闭合（Closed）"></a>闭合（Closed）</h2><p>熔断器闭合时系统能够正常发送请求，闭合状态下熔断器会维护一个最近失败的请求数量。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Counts holds the numbers of requests and their successes/failures.</span></span><br><span class="line"><span class="comment">// CircuitBreaker clears the internal Counts either</span></span><br><span class="line"><span class="comment">// on the change of the state or at the closed-state intervals.</span></span><br><span class="line"><span class="comment">// Counts ignores the results of the requests sent before clearing.</span></span><br><span class="line"><span class="keyword">type</span> Counts <span class="keyword">struct</span> &#123;</span><br><span class="line">	Requests             <span class="keyword">uint32</span></span><br><span class="line">	TotalSuccesses       <span class="keyword">uint32</span></span><br><span class="line">	TotalFailures        <span class="keyword">uint32</span></span><br><span class="line">	ConsecutiveSuccesses <span class="keyword">uint32</span></span><br><span class="line">	ConsecutiveFailures  <span class="keyword">uint32</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>每次请求到来时将会更新成功或者失败状态的数量。一旦请求失败数量超过某一个阈值，熔断器将会进入开启（Open）状态。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cb *CircuitBreaker)</span> <span class="title">onFailure</span><span class="params">(state State, now time.Time)</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> state &#123;</span><br><span class="line">	<span class="keyword">case</span> StateClosed:</span><br><span class="line">		cb.counts.onFailure()</span><br><span class="line">		<span class="keyword">if</span> cb.readyToTrip(cb.counts) &#123;</span><br><span class="line">			cb.setState(StateOpen, now)</span><br><span class="line">		&#125;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="开启（Open）"><a href="#开启（Open）" class="headerlink" title="开启（Open）"></a>开启（Open）</h2><p>熔断器开启后所有请求立刻失败并抛出异常。系统在设定开启状态时会给熔断器设置一个<code>expire time</code>，一旦熔断器处于开启状态时间超过<code>expire time</code>，将会自动转入半开状态。这样做的好处是可以让断路器自行检查下游服务可用性。</p>
<h2 id="半开（Half-open）"><a href="#半开（Half-open）" class="headerlink" title="半开（Half open）"></a>半开（Half open）</h2><p>一旦断路器开启状态超时便会进入半开状态。在半开状态下系统会限量发送请求，一旦请求连续成功达到某一个阈值，熔断器将会恢复闭合状态并发送所有请求。一旦有请求失败熔断器将回滚至开启状态并重置计时器。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cb *CircuitBreaker)</span> <span class="title">onSuccess</span><span class="params">(state State, now time.Time)</span></span> &#123;</span><br><span class="line">	<span class="comment">//...</span></span><br><span class="line">	<span class="keyword">case</span> StateHalfOpen:</span><br><span class="line">		cb.counts.onSuccess()</span><br><span class="line">		<span class="keyword">if</span> cb.counts.ConsecutiveSuccesses &gt;= cb.maxRequests &#123;</span><br><span class="line">			cb.setState(StateClosed, now)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>[1] <a href="https://github.com/sony/gobreaker" target="_blank" rel="noopener">https://github.com/sony/gobreaker</a> “Circuit Breaker implemented in Go”</li>
<li>[2] <a href="https://docs.microsoft.com/en-us/previous-versions/msp-n-p/dn589784(v=pandp.10)?redirectedfrom=MSDN" target="_blank" rel="noopener">https://docs.microsoft.com/en-us/previous-versions/msp-n-p/dn589784(v=pandp.10)?redirectedfrom=MSDN</a> “Circuit Breaker Pattern”</li>
</ul>
]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title>高并发系统的降级处理——限流</title>
    <url>/2019/12/11/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%99%8D%E7%BA%A7%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E9%99%90%E6%B5%81/</url>
    <content><![CDATA[<p>在服务器流量波动的情况下，我们需要根据下游服务器容量、业务要求等等对系统进行策略性的保护。保护策略有很多种，包括：</p>
<ol>
<li>限流（Rate limit）：限制系统输入输出以达到维持服务稳定的目的；</li>
<li>熔断（Circuit break）：在系统收到过多failing response的时候，拒绝系统输出；</li>
<li>减载（Load shedding）：在系统输入请求响应时间过长的时候，拒绝系统输入。</li>
</ol>
<p>一般来说，常见的限流算法有三种：滑动窗口（sliding window），漏桶（leaky bucket）以及令牌桶（token bucket）算法。</p>
<a id="more"></a>

<h1 id="滑动窗口（Sliding-Window）"><a href="#滑动窗口（Sliding-Window）" class="headerlink" title="滑动窗口（Sliding Window）"></a>滑动窗口（Sliding Window）</h1><p>滑动窗口算法比较简单粗暴。比方说我们需要100 qps的限流，我们将1s分为十个100ms的格子，格子之间通过链表（linkedlist）的方式连接。然后我们设置一个1s的窗口，每100ms在链表尾部新加一个格子，然后删掉队头的格子，保证1s的窗口内始终有十个格子。</p>
<p>每个格子内会记录到底的请求，请求到来的时候会首先查看当前1s内总访问量，如果超过100s则进入缓存等待或者丢弃，否则队尾格子进行计数。</p>
<p>滑动窗口算法的优势在于实现简单，内存友好。存在的问题是精度由格子的粒度决定。格子细粒度越高，窗口滑动越平滑，限流统计就越精确。</p>
<p><img alt="Sliding Window 原理图" title="Sliding Window 原理图" data-src="/images/sliding_window.jpeg" class="lazyload"></p>
<h1 id="漏桶（Leaky-Bucket）"><a href="#漏桶（Leaky-Bucket）" class="headerlink" title="漏桶（Leaky Bucket）"></a>漏桶（Leaky Bucket）</h1><p>漏桶算法<sup>[1]</sup>的核心逻辑为以下几点：</p>
<ol>
<li>实现了一个固定容量的桶；</li>
<li>桶的输出速率保证恒定，一旦桶内请求为空则停止输出；</li>
<li>一旦桶溢出，则溢出流量会被丢弃。</li>
</ol>
<p><img alt="Leaky Bucket 原理图" title="Leaky Bucket 原理图" data-src="/images/leaky_bucket.jpeg" class="lazyload"></p>
<p>漏桶的实现在单机上可以利用队列（queue）完成，分布式环境可以使用Redis或者其他消息中间件。</p>
<h1 id="令牌桶（Token-Bucket）"><a href="#令牌桶（Token-Bucket）" class="headerlink" title="令牌桶（Token Bucket）"></a>令牌桶（Token Bucket）</h1><p>令牌桶<sup>[1]</sup>根据令牌的数量来控制请求速率。每秒钟会平均往桶内放n个令牌，每次请求到达会消耗掉桶内X个令牌，一旦桶内剩余令牌≤X则请求放入缓存区等待或者丢弃。</p>
<p><img alt="[Token Bucket 原理图](https://www.quora.com/What-is-the-difference-between-token-bucket-and-leaky-bucket-algorithms)" title="Token Bucket 原理图" data-src="/images/token_bucket.gif" class="lazyload"></p>
<p>令牌桶对于不同突发状况有比较好的处理能力，以Google的Java开源项目<a href="https://github.com/google/guava/blob/master/guava/src/com/google/common/util/concurrent/RateLimiter.java" target="_blank" rel="noopener">Guava</a><sup>[4]</sup>为例，针对RateLimiter提供了两个实用的子类：平滑突发限流（SmoothBusrty）和平滑预热限流（SmoothWarmingUp）。</p>
<p>SmoothBursty能够很好地应对突发流量。当流量突然变大的时候，会立刻消耗掉桶内令牌，之后流量输出取决于令牌自增速率，达到一个平缓的输出速率；当流量突然变小的时候，流量会立即消耗掉桶内令牌。输出流量会呈现一个逼近恒定速率的趋势，但是具体速率由实时系统流量和令牌自增速率共同<strong>动态</strong>决定。</p>
<p>SmoothWarmingUp适用于<strong>下游服务需要预热</strong>的场景。创建限流器的时候可以设定参数如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 令牌自增速率为2个/秒，缓冲时间为3s</span></span><br><span class="line">RateLimiter r = RateLimiter.create(<span class="number">2</span>,<span class="number">3</span>,TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure>
<p>在这样的设置下，在前3s令牌不会每0.5s发放一次，而是会形成平缓线性下降的坡度。比方说1.5s发放第一个，0.9s发放第二个，0.6s发放第三个。在3s之后，发放速率会恢复设定的速率。</p>
<h1 id="漏桶-vs-令牌桶"><a href="#漏桶-vs-令牌桶" class="headerlink" title="漏桶 vs 令牌桶"></a>漏桶 vs 令牌桶</h1><ol>
<li>漏桶输出速率恒定，令牌桶输出速率由令牌自增速率与输入流量决定。增加令牌自增速率能够提高限流器上限。有突发流量（burst）时令牌桶输出速率可以动态提高</li>
<li>当漏桶满了之后，输入流量会被丢弃。当令牌桶满了之后，输入可以被缓存或者丢弃；</li>
</ol>
<p>一般来说漏桶被用在traffic policing的场景中，即network需要满足某一个contract，一旦超过contract，traffic shaping就会拒绝多余的流量请求，保证传输带宽；令牌桶多用在rate limit的场景中，更加灵活和动态。Uber的批处理系统中对限流的处理就运用到了这种令牌桶的设计原理。</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>[1] <a href="https://www.quora.com/What-is-the-difference-between-token-bucket-and-leaky-bucket-algorithms" target="_blank" rel="noopener">https://www.quora.com/What-is-the-difference-between-token-bucket-and-leaky-bucket-algorithms</a> “What is the difference between token bucket and leaky bucket algorithms?”</li>
<li>[2] <a href="https://www.figma.com/blog/an-alternative-approach-to-rate-limiting/" target="_blank" rel="noopener">https://www.figma.com/blog/an-alternative-approach-to-rate-limiting/</a> “An alternative approach to rate limiting”</li>
<li>[3] <a href="https://mp.weixin.qq.com/s/b4yqLSqNz7_vcGLRmhG0rw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/b4yqLSqNz7_vcGLRmhG0rw</a> “高并发系统中的限流应该如何做？”</li>
<li>[4] <a href="https://github.com/google/guava" target="_blank" rel="noopener">https://github.com/google/guava</a> “google/guava”</li>
</ul>
]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
</search>
