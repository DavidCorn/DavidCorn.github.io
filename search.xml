<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Golang调度器原理解析</title>
    <url>/2019/12/25/Golang%E8%B0%83%E5%BA%A6%E5%99%A8%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="什么是Goroutine"><a href="#什么是Goroutine" class="headerlink" title="什么是Goroutine"></a>什么是Goroutine</h3><p>Goroutine可以看作是轻量级的抽象thread。在编写Go代码的时候，我们会对Goroutine进行操作而不是针对thread。对于操作系统而言，thread是最小的调度单位。所以可以认为goroutine是用户层面的线程抽象。</p>
<h3 id="Goroutine和thread的区别"><a href="#Goroutine和thread的区别" class="headerlink" title="Goroutine和thread的区别"></a>Goroutine和thread的区别</h3><p>Goroutine与thread之间的区别<sup>[1]</sup>主要可以从三个方面出发，如下表所示：</p>
<table>
<thead>
<tr>
<th>区别</th>
<th>Goroutine</th>
<th>Thread</th>
</tr>
</thead>
<tbody><tr>
<td>内存占用</td>
<td>占用2KB栈内存，根据需要在运行中扩容</td>
<td>占用1MB左右内存，同时创建guard page与其他线程隔离</td>
</tr>
<tr>
<td>创建和销毁</td>
<td>Go runtime负责管理，用户级资源，创建销毁消耗非常小</td>
<td>内核级，消耗很大</td>
</tr>
<tr>
<td>切换成本</td>
<td>只需要保存三个寄存器 (register)，一般200ns左右</td>
<td>需要保存各种寄存器，消耗1000-1500ns</td>
</tr>
</tbody></table>
<h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p>关于调度器有三种基本模型：</p>
<ol>
<li>N:1。也就是多个用户线程对应一个系统线程。优势在于上下文切换快，缺点在于难以发挥多核处理器的优势；</li>
<li>1:1。也就是一个用户线程对应一个系统线程。牺牲上下文切换成本，充分利用多核处理器的优势；</li>
<li>M:N。理论上能在上下文切换和多核处理器之间找到平衡。</li>
</ol>
<p>Thread与Goroutine之间是一个M:N的关系。Go程序启动的时候，runtime会创建M个thread，之后创建的N个Goroutine会依附于这M个thread上执行。总的说来，Go runtime维护所有的Goroutine，通过scheduler进行调度。Goroutine与thread相互独立，但是Goroutine依托thread进行执行。</p>
<p>同一时刻一个thread上只能有一个Goroutine被执行。这时候什么thread上执行哪一个Goroutine，如何进行上下文的切换需要有一个中间人Scheduler做调度。Scheduler的调度也是Go程序高效执行的关键之一。</p>
<h2 id="调度器（Scheduler）"><a href="#调度器（Scheduler）" class="headerlink" title="调度器（Scheduler）"></a>调度器（Scheduler）</h2><h3 id="调度模型MPG"><a href="#调度模型MPG" class="headerlink" title="调度模型MPG"></a>调度模型MPG</h3><p>Golang的scheduler主要由三个部分组成：</p>
<ol>
<li>M（Machine）代表OS thread；</li>
<li>P（Processer）代表调度器（context for scheduling），通常P的数量等于CPU核数（<strong>GOMAXPROCS</strong>）；</li>
<li>G （Goroutine）代表Goroutine。</li>
</ol>
<p>他们的具体关系如下图所示<sup>[2]</sup>:</p>
<p><img alt="MPG Model" title="MPG Model" data-src="/images/mpg_scheduler.jpg" class="lazyload"></p>
<p>上图揭示了几个要点<sup>[3]</sup>：</p>
<ol>
<li>G需要绑定在M上才能运行；</li>
<li>M需要绑定在P上才能运行；</li>
<li>程序中多个M并不会同时处于运行状态，最多只有 <em>GOMAXPROCS</em> 个M在运行。</li>
</ol>
<p>在Go 1.1之前并没有P的存在。调度是由G与M共同完成。Global维护一个runqueue，当M需要G的时候便从runqueue中获取。这时候需要一个全局所来保护调度对象。很明显，全局锁的存在严重影响了Goroutine的并发性能。Go 1.1之后Dmitry Vyukov<sup>[4]</sup>设计了Processor对原先的Go scheduling进行了改进，使得每一个M上绑定一个P，P会维护一个runnable状态的G队列（Local Runnable Queue, LRQ），解决了原先全局锁的问题。</p>
<h3 id="调度算法（Work-stealing）"><a href="#调度算法（Work-stealing）" class="headerlink" title="调度算法（Work-stealing）"></a>调度算法（Work-stealing）</h3><p>通过引入P，实现的work-stealing调度算法如下：</p>
<ol>
<li>每一个P维护一个可运行队列LRQ；</li>
<li>当一个G生成时将其放入一个P的LRQ中；</li>
<li>当一个G执行结束时P会从队列中把G取出，如果P队列为空则会随机选择另外一个P偷取他一半的G；</li>
</ol>
<p>Work-stealing本质上来讲是一个负载均衡的算法。除了LRQ之外runttime也会维护一个GRQ（Global Runnable Queue）存放没有被分配具体P的G。</p>
<h3 id="同步系统调度（Blocking-System-Call）"><a href="#同步系统调度（Blocking-System-Call）" class="headerlink" title="同步系统调度（Blocking System Call）"></a>同步系统调度（Blocking System Call）</h3><p>之所以P存在，是当有M被sysCall block的时候，我们能够把整个P交给另外一个M继续执行。当sysCall执行完毕后M会偷取其他的P，如果无法找到合适的P，M会进入线程池休眠。</p>
<p><img alt="Blocking System Call" title="Blocking System Call" data-src="/images/syscall.jpg" class="lazyload"></p>
<h3 id="异步系统调度（Asyn-System-Call）"><a href="#异步系统调度（Asyn-System-Call）" class="headerlink" title="异步系统调度（Asyn System Call）"></a>异步系统调度（Asyn System Call）</h3><p>如果是异步调用，M不会被阻塞。如图所示，G1的异步请求会被Network Poll接手，M此时会继续执行G2，当G1异步请求完成，会自动放回P的LRQ中，整个过程如下图所示<sup>[5]</sup>。</p>
<p><img alt="Async System Call" title="Async System Call" data-src="/images/async_syscall.png" class="lazyload"></p>
<h3 id="抢占式调度（Takeover）"><a href="#抢占式调度（Takeover）" class="headerlink" title="抢占式调度（Takeover）"></a>抢占式调度（Takeover）</h3><p>Goroutine的执行是可以被抢占<sup>[3]</sup>的。简单来说，如果一个Goroutine占用CPU时间过长（&gt; 10ms），P长时间没有进行调度，runtime会将其抢占，把CPU时间交给其他Goroutine。</p>
<p>具体来看，runtime启动时，程序会创建一个系统线程，运行<code>sysmon()</code>函数，负责监控所有Goroutine的状态同时判断是否需要进行垃圾回收。如果G执行时间过长，<code>sysmon()</code>会对这个G进行标记，下一次函数调用的时候会自动失败，并且和对应的M解除绑定关系并移送全局可执行队列GRQ中，然后为P设置新的可执行G。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Go并发效率如此之高，我们可以做一个简单的总结：</p>
<ol>
<li>Goroutine相较线程来看更为轻量，创建、销毁以及上下文切换开销小很多；</li>
<li>Scheduler实现了M:N的调度模式（并行能力由GOMAXPROCS决定，也就是多少个Processor），兼顾N:1，1:1调度模型优点，整体运行效率比线程调度高很多。</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>[1] <a href="https://blog.nindalf.com/posts/how-goroutines-work/" target="_blank" rel="noopener">https://blog.nindalf.com/posts/how-goroutines-work/</a> “How Goroutines Work”</li>
<li>[2] <a href="https://morsmachine.dk/go-scheduler" target="_blank" rel="noopener">https://morsmachine.dk/go-scheduler</a> “The Go scheduler”</li>
<li>[3] <a href="https://cloud.tencent.com/developer/article/1165575" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1165575</a> “Go runtime scheduler”</li>
<li>[4] <a href="https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit" target="_blank" rel="noopener">https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit</a> “Scalable Go Scheduler Design Doc”</li>
<li>[5] <a href="https://qcrao.com/2019/09/02/dive-into-go-scheduler/" target="_blank" rel="noopener">https://qcrao.com/2019/09/02/dive-into-go-scheduler/</a> “深度解密Go语言之scheduler”</li>
</ul>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title>高并发系统的降级处理——减载</title>
    <url>/2019/12/19/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%99%8D%E7%BA%A7%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E5%87%8F%E8%BD%BD/</url>
    <content><![CDATA[<p>在服务器流量波动的情况下，我们需要根据下游服务器容量、业务要求等等对系统进行策略性的保护。保护策略有很多种，包括：</p>
<ol>
<li>限流（Rate limit）：限制系统输入输出以达到维持服务稳定的目的；</li>
<li>熔断（Circuit break）：在系统受到过多failing response的时候，拒绝系统输出；</li>
<li>减载（Load shedding）：在系统输入请求响应时间过长的时候，拒绝系统输入。</li>
</ol>
<p>一旦系统处理速度小于系统每秒接收的请求数量（processing speed &lt; QPS），内存队列中的请求将逐渐累积，当请求不断增加没有及时释放，系统会遇到延迟增高，阻塞，内存溢出等等问题。因此系统可以建立一种机制，在响应时间变长时拒绝接收请求防止系统过载。</p>
<p>Facebook 有一篇非常有名的paper <sup>[1]</sup>提供了集中策略来设计系统减载方案（loadshedding）。主要里用到的技术包含Control Delay（CoDel）和Adaptive LIFO。</p>
<h1 id="Control-Delay"><a href="#Control-Delay" class="headerlink" title="Control Delay"></a>Control Delay</h1><p>一般来说服务器会有内存或者资源池数量的限制，并将没有来得及处理的请求放在缓冲区。一旦处理请求的速度跟不上到来的请求，队列将会越来越大并且最终超过使用闲置。Facebook根据CoDel的启发设计了一套算法：</p>
<ol>
<li>当内存缓冲队列在过去的N毫秒内没有被清空，则queue中请求的timeout则被设置为M毫秒（一般为10-30ms）；</li>
<li>(Optional) 当内存缓冲队列在过去的N毫秒内被清空，则queue中请求的timeout被设置成N毫秒。</li>
</ol>
<p>伪代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">onNewRequest</span><span class="params">(req, queue)</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (queue.lastEmptyTime() &lt; (now - N seconds)) &#123;</span><br><span class="line">     timeout = M ms</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     timeout = N seconds;</span><br><span class="line">  &#125;</span><br><span class="line">  queue.enqueue(req, timeout)</span><br></pre></td></tr></table></figure>

<h1 id="Adaptive-LIFO"><a href="#Adaptive-LIFO" class="headerlink" title="Adaptive LIFO"></a>Adaptive LIFO</h1><p>大部分系统处理请求遵循FIFO (First In Last Out) 原则。在峰值流量太大时，后来的请求可能会因为先来请求的阻塞而导致请求耗时更长。对此Facebook提出的方案是adaptive LIFO (Last In First Out) ，当系统出现队列请求积压的时候，将队列模式自动切换为LIFO，后到的请求首先执行，最大限度上增加了请求成功的可能性。</p>
<p>Adaptive LIFO与CoDel能够非常好的兼容，如下图所示。CoDel设置较短timeout，防止队列积压过多请求，adaptive LIFO将后入的请求率先处理，最大限度增加请求成功的概率。Facebook的PHP runtime virtual machine <sup>[2]</sup>以及thrift <sup>[3]</sup> framework都用到了这种算法。</p>
<p><img alt="Adaptive LIFO" title="Adaptive LIFO" data-src="/images/adaptive_lifo.png" class="lazyload"></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>[1] <a href="https://queue.acm.org/detail.cfm?id=2839461" target="_blank" rel="noopener">https://queue.acm.org/detail.cfm?id=2839461</a> “Fail at Scale”</li>
<li>[2] <a href="https://github.com/facebook/hhvm/blob/43c20856239cedf842b2560fd768038f52b501db/hphp/util/job-queue.h#L75" target="_blank" rel="noopener">https://github.com/facebook/hhvm/blob/43c20856239cedf842b2560fd768038f52b501db/hphp/util/job-queue.h#L75</a> “A virtual machine for executing programs written in Hack”</li>
<li>[3] <a href="https://github.com/facebook/fbthrift" target="_blank" rel="noopener">https://github.com/facebook/fbthrift</a> “Facebook Thrift”</li>
</ul>
]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title>高并发系统的降级处理——熔断</title>
    <url>/2019/12/15/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%99%8D%E7%BA%A7%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E7%86%94%E6%96%AD/</url>
    <content><![CDATA[<p>在服务器流量波动的情况下，我们需要根据下游服务器容量、业务要求等等对系统进行策略性的保护。保护策略有很多种，包括：</p>
<ol>
<li>限流（Rate limit）：限制系统输入输出以达到维持服务稳定的目的；</li>
<li>熔断（Circuit break）：在系统受到过多failing response的时候，拒绝系统输出；</li>
<li>减载（Load shedding）：在系统输入请求响应时间过长的时候，拒绝系统输入。</li>
</ol>
<p>熔断的作用是阻止服务发送过多可能失败的请求 (The Circuit Breaker pattern prevents an application from performing an operation that is likely to fail)。本文从开源代码 <a href="https://github.com/sony/gobreaker" target="_blank" rel="noopener">sony/gobreaker</a> <sup>[1]</sup>出发，介绍熔断器的工作原理和机制。</p>
<h1 id="设计要求-Requirements"><a href="#设计要求-Requirements" class="headerlink" title="设计要求 (Requirements)"></a>设计要求 (Requirements)</h1><p>分布式系统中，一般的故障场景例如网络波动（slow network connection），请求超时（timeout）或者过载（overload）等等都可能是暂时性的问题，能够通过系统自修复或者云系统的延展性（horizontal/vertical scaling）等等方式解决。熔断器（Circuit Breaker）是为了解决一些不可预测、难以自修复的故障，比如系统下游服务不可用，数据库宕机等等。另外，熔断器也能有效地阻止连锁反应（cascading failure）的发生。比如当网关（gateway）某一个下游服务不可用，系统不断发送请求并不断重试，可能会导致网关服务占用过多资源内存导致整体崩溃；下游服务如果只是部分不可用，过多的失败请求也会导致下游服务崩溃。</p>
<p>设计一个熔断器要求能够在故障时迅速反应，并且在故障恢复后能够自动恢复。</p>
<h1 id="状态机-State-machine"><a href="#状态机-State-machine" class="headerlink" title="状态机 (State machine)"></a>状态机 (State machine)</h1><p>熔断器其实是一个小型的状态机，随着请求返回状态码动态进行状态的调整。状态可以分为三类：闭合（Closed），开启（Open），半开（Half-open）。相互关系如下图<sup>[2]</sup>所示。</p>
<p><img alt="Circuit breaker state machine" title="Circuit breaker state machine" data-src="/images/circuit_breaker.png" class="lazyload"></p>
<p>每次请求到来的时候熔断器会有两个内置函数<code>before_request</code>以及<code>after_request</code>。<code>before_request</code>在请求前进行调用，根据状态决定是否截断请求，并记录请求数量。<code>after_request</code>作用在请求结束之后，负责根据请求返回状态码进行状态和计数器的更新。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Execute runs the given request if the CircuitBreaker accepts it.</span></span><br><span class="line"><span class="comment">// Execute returns an error instantly if the CircuitBreaker rejects the request.</span></span><br><span class="line"><span class="comment">// Otherwise, Execute returns the result of the request.</span></span><br><span class="line"><span class="comment">// If a panic occurs in the request, the CircuitBreaker handles it as an error</span></span><br><span class="line"><span class="comment">// and causes the same panic again.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cb *CircuitBreaker)</span> <span class="title">Execute</span><span class="params">(req <span class="keyword">func</span>()</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span>) <span class="params">(<span class="keyword">interface</span>&#123;&#125;, error)</span></span> &#123;</span><br><span class="line">	generation, err := cb.beforeRequest()</span><br><span class="line">	<span class="comment">//...</span></span><br><span class="line">	</span><br><span class="line">	<span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		e := <span class="built_in">recover</span>()</span><br><span class="line">		<span class="keyword">if</span> e != <span class="literal">nil</span> &#123;</span><br><span class="line">			cb.afterRequest(generation, <span class="literal">false</span>)</span><br><span class="line">			<span class="built_in">panic</span>(e)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line"></span><br><span class="line">	cb.afterRequest(generation, err == <span class="literal">nil</span>)</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="闭合（Closed）"><a href="#闭合（Closed）" class="headerlink" title="闭合（Closed）"></a>闭合（Closed）</h2><p>熔断器闭合时系统能够正常发送请求，闭合状态下熔断器会维护一个最近失败的请求数量。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Counts holds the numbers of requests and their successes/failures.</span></span><br><span class="line"><span class="comment">// CircuitBreaker clears the internal Counts either</span></span><br><span class="line"><span class="comment">// on the change of the state or at the closed-state intervals.</span></span><br><span class="line"><span class="comment">// Counts ignores the results of the requests sent before clearing.</span></span><br><span class="line"><span class="keyword">type</span> Counts <span class="keyword">struct</span> &#123;</span><br><span class="line">	Requests             <span class="keyword">uint32</span></span><br><span class="line">	TotalSuccesses       <span class="keyword">uint32</span></span><br><span class="line">	TotalFailures        <span class="keyword">uint32</span></span><br><span class="line">	ConsecutiveSuccesses <span class="keyword">uint32</span></span><br><span class="line">	ConsecutiveFailures  <span class="keyword">uint32</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>每次请求到来时将会更新成功或者失败状态的数量。一旦请求失败数量超过某一个阈值，熔断器将会进入开启（Open）状态。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cb *CircuitBreaker)</span> <span class="title">onFailure</span><span class="params">(state State, now time.Time)</span></span> &#123;</span><br><span class="line">	<span class="keyword">switch</span> state &#123;</span><br><span class="line">	<span class="keyword">case</span> StateClosed:</span><br><span class="line">		cb.counts.onFailure()</span><br><span class="line">		<span class="keyword">if</span> cb.readyToTrip(cb.counts) &#123;</span><br><span class="line">			cb.setState(StateOpen, now)</span><br><span class="line">		&#125;</span><br><span class="line">	<span class="comment">// ...</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="开启（Open）"><a href="#开启（Open）" class="headerlink" title="开启（Open）"></a>开启（Open）</h2><p>熔断器开启后所有请求立刻失败并抛出异常。系统在设定开启状态时会给熔断器设置一个<code>expire time</code>，一旦熔断器处于开启状态时间超过<code>expire time</code>，将会自动转入半开状态。这样做的好处是可以让断路器自行检查下游服务可用性。</p>
<h2 id="半开（Half-open）"><a href="#半开（Half-open）" class="headerlink" title="半开（Half open）"></a>半开（Half open）</h2><p>一旦断路器开启状态超时便会进入半开状态。在半开状态下系统会限量发送请求，一旦请求连续成功达到某一个阈值，熔断器将会恢复闭合状态并发送所有请求。一旦有请求失败熔断器将回滚至开启状态并重置计时器。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cb *CircuitBreaker)</span> <span class="title">onSuccess</span><span class="params">(state State, now time.Time)</span></span> &#123;</span><br><span class="line">	<span class="comment">//...</span></span><br><span class="line">	<span class="keyword">case</span> StateHalfOpen:</span><br><span class="line">		cb.counts.onSuccess()</span><br><span class="line">		<span class="keyword">if</span> cb.counts.ConsecutiveSuccesses &gt;= cb.maxRequests &#123;</span><br><span class="line">			cb.setState(StateClosed, now)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>[1] <a href="https://github.com/sony/gobreaker" target="_blank" rel="noopener">https://github.com/sony/gobreaker</a> “Circuit Breaker implemented in Go”</li>
<li>[2] <a href="https://docs.microsoft.com/en-us/previous-versions/msp-n-p/dn589784(v=pandp.10)?redirectedfrom=MSDN" target="_blank" rel="noopener">https://docs.microsoft.com/en-us/previous-versions/msp-n-p/dn589784(v=pandp.10)?redirectedfrom=MSDN</a> “Circuit Breaker Pattern”</li>
</ul>
]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title>高并发系统的降级处理——限流</title>
    <url>/2019/12/11/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E7%9A%84%E9%99%8D%E7%BA%A7%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E9%99%90%E6%B5%81/</url>
    <content><![CDATA[<p>在服务器流量波动的情况下，我们需要根据下游服务器容量、业务要求等等对系统进行策略性的保护。保护策略有很多种，包括：</p>
<ol>
<li>限流（Rate limit）：限制系统输入输出以达到维持服务稳定的目的；</li>
<li>熔断（Circuit break）：在系统收到过多failing response的时候，拒绝系统输出；</li>
<li>减载（Load shedding）：在系统输入请求响应时间过长的时候，拒绝系统输入。</li>
</ol>
<p>一般来说，常见的限流算法有三种：滑动窗口（sliding window），漏桶（leaky bucket）以及令牌桶（token bucket）算法。</p>
<a id="more"></a>

<h1 id="滑动窗口（Sliding-Window）"><a href="#滑动窗口（Sliding-Window）" class="headerlink" title="滑动窗口（Sliding Window）"></a>滑动窗口（Sliding Window）</h1><p>滑动窗口算法比较简单粗暴。比方说我们需要100 qps的限流，我们将1s分为十个100ms的格子，格子之间通过链表（linkedlist）的方式连接。然后我们设置一个1s的窗口，每100ms在链表尾部新加一个格子，然后删掉队头的格子，保证1s的窗口内始终有十个格子。</p>
<p>每个格子内会记录到底的请求，请求到来的时候会首先查看当前1s内总访问量，如果超过100s则进入缓存等待或者丢弃，否则队尾格子进行计数。</p>
<p>滑动窗口算法的优势在于实现简单，内存友好。存在的问题是精度由格子的粒度决定。格子细粒度越高，窗口滑动越平滑，限流统计就越精确。</p>
<p><img alt="Sliding Window 原理图" title="Sliding Window 原理图" data-src="/images/sliding_window.jpeg" class="lazyload"></p>
<h1 id="漏桶（Leaky-Bucket）"><a href="#漏桶（Leaky-Bucket）" class="headerlink" title="漏桶（Leaky Bucket）"></a>漏桶（Leaky Bucket）</h1><p>漏桶算法<sup>[1]</sup>的核心逻辑为以下几点：</p>
<ol>
<li>实现了一个固定容量的桶；</li>
<li>桶的输出速率保证恒定，一旦桶内请求为空则停止输出；</li>
<li>一旦桶溢出，则溢出流量会被丢弃。</li>
</ol>
<p><img alt="Leaky Bucket 原理图" title="Leaky Bucket 原理图" data-src="/images/leaky_bucket.jpeg" class="lazyload"></p>
<p>漏桶的实现在单机上可以利用队列（queue）完成，分布式环境可以使用Redis或者其他消息中间件。</p>
<h1 id="令牌桶（Token-Bucket）"><a href="#令牌桶（Token-Bucket）" class="headerlink" title="令牌桶（Token Bucket）"></a>令牌桶（Token Bucket）</h1><p>令牌桶<sup>[1]</sup>根据令牌的数量来控制请求速率。每秒钟会平均往桶内放n个令牌，每次请求到达会消耗掉桶内X个令牌，一旦桶内剩余令牌≤X则请求放入缓存区等待或者丢弃。</p>
<p><img alt="[Token Bucket 原理图](https://www.quora.com/What-is-the-difference-between-token-bucket-and-leaky-bucket-algorithms)" title="Token Bucket 原理图" data-src="/images/token_bucket.gif" class="lazyload"></p>
<p>令牌桶对于不同突发状况有比较好的处理能力，以Google的Java开源项目<a href="https://github.com/google/guava/blob/master/guava/src/com/google/common/util/concurrent/RateLimiter.java" target="_blank" rel="noopener">Guava</a><sup>[4]</sup>为例，针对RateLimiter提供了两个实用的子类：平滑突发限流（SmoothBusrty）和平滑预热限流（SmoothWarmingUp）。</p>
<p>SmoothBursty能够很好地应对突发流量。当流量突然变大的时候，会立刻消耗掉桶内令牌，之后流量输出取决于令牌自增速率，达到一个平缓的输出速率；当流量突然变小的时候，流量会立即消耗掉桶内令牌。输出流量会呈现一个逼近恒定速率的趋势，但是具体速率由实时系统流量和令牌自增速率共同<strong>动态</strong>决定。</p>
<p>SmoothWarmingUp适用于<strong>下游服务需要预热</strong>的场景。创建限流器的时候可以设定参数如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 令牌自增速率为2个/秒，缓冲时间为3s</span></span><br><span class="line">RateLimiter r = RateLimiter.create(<span class="number">2</span>,<span class="number">3</span>,TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure>
<p>在这样的设置下，在前3s令牌不会每0.5s发放一次，而是会形成平缓线性下降的坡度。比方说1.5s发放第一个，0.9s发放第二个，0.6s发放第三个。在3s之后，发放速率会恢复设定的速率。</p>
<h1 id="漏桶-vs-令牌桶"><a href="#漏桶-vs-令牌桶" class="headerlink" title="漏桶 vs 令牌桶"></a>漏桶 vs 令牌桶</h1><ol>
<li>漏桶输出速率恒定，令牌桶输出速率由令牌自增速率与输入流量决定。增加令牌自增速率能够提高限流器上限。有突发流量（burst）时令牌桶输出速率可以动态提高</li>
<li>当漏桶满了之后，输入流量会被丢弃。当令牌桶满了之后，输入可以被缓存或者丢弃；</li>
</ol>
<p>一般来说漏桶被用在traffic policing的场景中，即network需要满足某一个contract，一旦超过contract，traffic shaping就会拒绝多余的流量请求，保证传输带宽；令牌桶多用在rate limit的场景中，更加灵活和动态。Uber的批处理系统中对限流的处理就运用到了这种令牌桶的设计原理。</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li>[1] <a href="https://www.quora.com/What-is-the-difference-between-token-bucket-and-leaky-bucket-algorithms" target="_blank" rel="noopener">https://www.quora.com/What-is-the-difference-between-token-bucket-and-leaky-bucket-algorithms</a> “What is the difference between token bucket and leaky bucket algorithms?”</li>
<li>[2] <a href="https://www.figma.com/blog/an-alternative-approach-to-rate-limiting/" target="_blank" rel="noopener">https://www.figma.com/blog/an-alternative-approach-to-rate-limiting/</a> “An alternative approach to rate limiting”</li>
<li>[3] <a href="https://mp.weixin.qq.com/s/b4yqLSqNz7_vcGLRmhG0rw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/b4yqLSqNz7_vcGLRmhG0rw</a> “高并发系统中的限流应该如何做？”</li>
<li>[4] <a href="https://github.com/google/guava" target="_blank" rel="noopener">https://github.com/google/guava</a> “google/guava”</li>
</ul>
]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
      <tags>
        <tag>高并发</tag>
      </tags>
  </entry>
</search>
